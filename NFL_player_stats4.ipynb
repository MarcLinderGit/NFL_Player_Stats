{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.nfl.com\"\n",
    "current_week = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to get links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(level, base_url=\"https://www.nfl.com\"):\n",
    "    if level == \"player\":\n",
    "        # URL for player-level stats\n",
    "        url = \"https://www.nfl.com/stats/player-stats\"\n",
    "    elif level == \"team\":\n",
    "        unit_list = [\"offense\", \"defense\", \"special-teams\"]\n",
    "        category_links = {}\n",
    "        stat_cols = {\n",
    "            \"offense\": [\"passing\", \"rushing\", \"receiving\", \"scoring\", \"downs\"],\n",
    "            \"defense\": [\"passing\", \"rushing\", \"receiving\", \"scoring\", \"tackles\", \"downs\", \"fumbles\", \"interceptions\"],\n",
    "            \"special-teams\": [\"field-goals\", \"scoring\", \"kickoffs\", \"kickoff-returns\", \"punting\", \"punt-returns\"]\n",
    "        }\n",
    "\n",
    "        base_team_stats_url = \"https://www.nfl.com/stats/team-stats/\"\n",
    "\n",
    "        for unit in unit_list:\n",
    "            unit_data = {}\n",
    "            for stat_col in stat_cols[unit]:\n",
    "                # Construct the URL for each category in stat_cols\n",
    "                url = f\"{base_team_stats_url}{unit}/2023/{stat_col}\"\n",
    "                unit_data[stat_col.capitalize()] = url\n",
    "\n",
    "            # Add the unit's data to the main dictionary\n",
    "            category_links[unit.capitalize()] = unit_data\n",
    "        return category_links\n",
    "\n",
    "    # For all other cases (invalid level), fetch general category links\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "    a_elements = soup.find_all('li', class_='d3-o-tabs__list-item')\n",
    "    tabs = [element.find('a').get_text() for element in a_elements]\n",
    "    links = [base_url + element.find('a')['href'] for element in a_elements]\n",
    "    print(links)\n",
    "\n",
    "    return dict(zip(tabs, links))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function to format links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_links_old(level):\n",
    "    # Create a dictionary to store the links for each unit and its categories\n",
    "    unit_links = {}\n",
    "    lst = [\"offense\", \"defense\", \"special-teams\"]\n",
    "\n",
    "    # Process the URL and build the unit_links dictionary\n",
    "    if level == \"player\":\n",
    "        # Define the URL for the player level\n",
    "        url = \"https://www.nfl.com\"\n",
    "        unit_links = get_links(level, url)  # Pass the URL as an argument\n",
    "\n",
    "    if level == \"team\":\n",
    "        for unit in lst:\n",
    "            # Initialize an empty dictionary for the current unit\n",
    "            unit_data = {}\n",
    "            \n",
    "            # Define the URL for the current unit\n",
    "            url = f\"https://www.nfl.com/stats/team-stats/{unit.lower()}/2023\"\n",
    "            category_links = get_links(level, url)  # Pass the URL as an argument\n",
    "\n",
    "            # Assuming category_links is your nested dictionary\n",
    "            for unit, categories in category_links.items():\n",
    "                for category, link in categories.items():\n",
    "                    # Remove '/2023' from the link first\n",
    "                    link = link.replace('/2023', '')\n",
    "                    # Append '/2023/reg/all' to the modified link\n",
    "                    category_links[unit][category] = f\"{link}/2023/reg/all\"\n",
    "\n",
    "\n",
    "            print('category links are: ', category_links) \n",
    "            # Add the category links to the unit_data dictionary\n",
    "            #unit_data.update(category_links)\n",
    "            \n",
    "            # Add the unit_data dictionary to the unit_links dictionary\n",
    "            unit_links = category_links\n",
    "            #unit_links[unit.capitalize()] = unit_data\n",
    "\n",
    "    return unit_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated format_links function\n",
    "def format_links(level):\n",
    "    # Create a dictionary to store the links for each unit and its categories\n",
    "    unit_links = {}\n",
    "    base_url = \"https://www.nfl.com\"  # Replace with your base URL\n",
    "\n",
    "    if level == \"player\":\n",
    "        # Define the URL for the player level\n",
    "        url = \"https://www.nfl.com\"\n",
    "        unit_links = get_links(level, url)  # Pass the URL as an argument\n",
    "\n",
    "    if level == \"team\":\n",
    "        # First get the base links for offense, defense, and special-teams tab\n",
    "        # Request raw HTML\n",
    "        html = requests.get(\"https://www.nfl.com/stats/team-stats/\")\n",
    "\n",
    "        # Assuming your HTML is stored in a variable named html_content\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "\n",
    "        # Find the ul element with class 'd3-o-tabbed-controls-selector__list'\n",
    "        ul_element = soup.find('ul', class_='d3-o-tabbed-controls-selector__list')\n",
    "\n",
    "        # Find all li elements within the ul element\n",
    "        li_elements = ul_element.find_all('li')\n",
    "\n",
    "        # Initialize a list to store the href values\n",
    "        href_values = []\n",
    "\n",
    "        # Iterate through the li elements and extract the href values from the a tags\n",
    "        for li in li_elements:\n",
    "            a_tag = li.find('a')\n",
    "            if a_tag:\n",
    "                href = a_tag['href']\n",
    "                href_values.append(href)\n",
    "\n",
    "        # Initialize a list to store the links\n",
    "        all_links = []\n",
    "\n",
    "        # Loop through href_values and fetch links for each URL\n",
    "        for href in href_values:\n",
    "            url = base_url + href\n",
    "            html = requests.get(url)\n",
    "            soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "            a_elements = soup.find_all('li', class_='d3-o-tabs__list-item')\n",
    "            links = [base_url + element.find('a')['href'] for element in a_elements]\n",
    "            all_links.extend(links)  # Append the links to the all_links list\n",
    "\n",
    "        # Create a dictionary to store the links\n",
    "        team_stats_dict = {}\n",
    "\n",
    "        for link in all_links:\n",
    "            # Split the link by \"/\"\n",
    "            parts = link.split('/')\n",
    "            # Get the keys and values\n",
    "            unit = parts[5] # e.g., offense, defense, special-teams\n",
    "            category = parts[6] # e.g., passing, rushing etc.\n",
    "            year = parts[7] # 2023\n",
    "            leg = parts[8] # reg of playoffs\n",
    "            url = link\n",
    "            # Add to the dictionary\n",
    "            if unit not in team_stats_dict:\n",
    "                team_stats_dict[unit] = {}\n",
    "            team_stats_dict[unit][category] = url\n",
    "\n",
    "        # Update unit_links with the fetched links\n",
    "        unit_links = team_stats_dict\n",
    "\n",
    "    return unit_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scrape and export to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function to Check/Create Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create directories if they don't exist\n",
    "def create_directory_if_not_exists(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        try:\n",
    "            os.makedirs(directory_path)\n",
    "            print(f'Directory \"{directory_path}\" has been created.')\n",
    "        except OSError as e:\n",
    "            print(f'Error: Failed to create directory \"{directory_path}\".')\n",
    "            print(e)\n",
    "    else:\n",
    "        print(f'Directory \"{directory_path}\" already exists.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function to Scrape and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape and process data\n",
    "def scrape_and_process_data(link, unit, category, level, unit_directory_path):\n",
    "    # Request raw HTML for the current page\n",
    "    response = requests.get(link)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Create a BeautifulSoup object to parse the HTML\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Find all elements with the class 'd3-o-player-stats--detailed'\n",
    "        stats = soup.find_all(attrs={\"class\": f'd3-o-{level}-stats--detailed'})\n",
    "\n",
    "        # Initialize lists to collect data\n",
    "        stat_val = []\n",
    "        stat_col = []\n",
    "\n",
    "        # Loop through each <tr> element to extract and collect the text from <td> elements\n",
    "        for row in stats:\n",
    "            # This gets the stat names\n",
    "            header_cells = row.find_all('th')\n",
    "\n",
    "            if len(header_cells) > 0:\n",
    "                for cell in header_cells:\n",
    "                    stat_col.append(cell.get_text(strip=True))\n",
    "\n",
    "            # This gets the stats\n",
    "            data_cells = row.find_all('td')\n",
    "\n",
    "            if len(data_cells) > 0:\n",
    "                for cell in data_cells:\n",
    "                    stat_val.append(cell.get_text(strip=True))\n",
    "\n",
    "        # Determine the number of columns in each row\n",
    "        num_columns = len(stat_col) if stat_col else 1  # Use 1 if stat_col is empty\n",
    "        \n",
    "        # Split the list into rows\n",
    "        rows = [stat_val[i:i + num_columns] for i in range(0, len(stat_val), num_columns)]\n",
    "\n",
    "        # Create a DataFrame for the current category\n",
    "        df = pd.DataFrame(rows, columns=stat_col)\n",
    "        # Convert all columns except \"Team\" to numeric\n",
    "        #numeric_columns = df.columns.difference(['Team'])\n",
    "        #df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        # Check if the DataFrame has a \"Team\" column before attempting to remove the duplicated part\n",
    "        if 'Team' in df.columns:\n",
    "            # Remove duplicated part from the \"Team\" column\n",
    "            df['Team'] = df['Team'].apply(lambda x: x[:len(x)//2])\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        create_directory_if_not_exists(unit_directory_path)\n",
    "    \n",
    "        \n",
    "        # Specify the file path within the unit's directory\n",
    "        csv_file_path = os.path.join(unit_directory_path, category + '.csv')\n",
    "\n",
    "        # Export the DataFrame to a CSV file\n",
    "        df.to_csv(csv_file_path, index=False)  # Set index=False to exclude the index column\n",
    "\n",
    "        print(f'DataFrame for category \"{category}\" in unit \"{unit}\" has been exported to {csv_file_path}')\n",
    "    else:\n",
    "        print(f\"Error: Unable to fetch the page for category '{category}' in unit '{unit}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate Scraping Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(level):\n",
    "    lst = [\"offense\", \"defense\", \"special-teams\"]\n",
    "\n",
    "    # Combine the base directory path with the current week\n",
    "    directory_path = os.path.join('data', level, 'week' + str(current_week))\n",
    "    unit_links = format_links(level)\n",
    "\n",
    "    if level == \"team\":\n",
    "        for unit, categories in unit_links.items(): ## change to be same with player\n",
    "            for category, link in categories.items():\n",
    "\n",
    "                # Create a subdirectory for the current unit\n",
    "                unit_directory_path = os.path.join(directory_path, unit)\n",
    "                create_directory_if_not_exists(unit_directory_path)\n",
    "\n",
    "                # Call scrape_and_process_data with individual category URLs\n",
    "                scrape_and_process_data(link, unit, category, level, unit_directory_path)\n",
    "                \n",
    "    elif level == \"player\":\n",
    "        # Directly use the week1 directory for player-level data\n",
    "        unit_directory_path = directory_path\n",
    "\n",
    "        # Call scrape_and_process_data with the unit_links dictionary\n",
    "\n",
    "        for category, link in unit_links.items():\n",
    "            scrape_and_process_data(link, level, category, level, unit_directory_path)\n",
    "    else:\n",
    "        print(\"Invalid level specified.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.nfl.com/stats/player-stats/category/passing/2023/reg/all/passingyards/desc', 'https://www.nfl.com/stats/player-stats/category/rushing/2023/reg/all/rushingyards/desc', 'https://www.nfl.com/stats/player-stats/category/receiving/2023/reg/all/receivingreceptions/desc', 'https://www.nfl.com/stats/player-stats/category/fumbles/2023/reg/all/defensiveforcedfumble/desc', 'https://www.nfl.com/stats/player-stats/category/tackles/2023/reg/all/defensivecombinetackles/desc', 'https://www.nfl.com/stats/player-stats/category/interceptions/2023/reg/all/defensiveinterceptions/desc', 'https://www.nfl.com/stats/player-stats/category/field-goals/2023/reg/all/kickingfgmade/desc', 'https://www.nfl.com/stats/player-stats/category/kickoffs/2023/reg/all/kickofftotal/desc', 'https://www.nfl.com/stats/player-stats/category/kickoff-returns/2023/reg/all/kickreturnsaverageyards/desc', 'https://www.nfl.com/stats/player-stats/category/punts/2023/reg/all/puntingaverageyards/desc', 'https://www.nfl.com/stats/player-stats/category/punt-returns/2023/reg/all/puntreturnsaverageyards/desc']\n",
      "Directory \"data\\player\\week1\" has been created.\n",
      "DataFrame for category \"Passing\" in unit \"player\" has been exported to data\\player\\week1\\Passing.csv\n",
      "Directory \"data\\player\\week1\" already exists.\n",
      "DataFrame for category \"Rushing\" in unit \"player\" has been exported to data\\player\\week1\\Rushing.csv\n",
      "Directory \"data\\player\\week1\" already exists.\n",
      "DataFrame for category \"Receiving\" in unit \"player\" has been exported to data\\player\\week1\\Receiving.csv\n",
      "Directory \"data\\player\\week1\" already exists.\n",
      "DataFrame for category \"Fumbles\" in unit \"player\" has been exported to data\\player\\week1\\Fumbles.csv\n",
      "Directory \"data\\player\\week1\" already exists.\n",
      "DataFrame for category \"Tackles\" in unit \"player\" has been exported to data\\player\\week1\\Tackles.csv\n",
      "Directory \"data\\player\\week1\" already exists.\n",
      "DataFrame for category \"Interceptions\" in unit \"player\" has been exported to data\\player\\week1\\Interceptions.csv\n",
      "Directory \"data\\player\\week1\" already exists.\n",
      "DataFrame for category \"Field Goals\" in unit \"player\" has been exported to data\\player\\week1\\Field Goals.csv\n",
      "Directory \"data\\player\\week1\" already exists.\n",
      "DataFrame for category \"Kickoffs\" in unit \"player\" has been exported to data\\player\\week1\\Kickoffs.csv\n",
      "Directory \"data\\player\\week1\" already exists.\n",
      "DataFrame for category \"Kickoff Returns\" in unit \"player\" has been exported to data\\player\\week1\\Kickoff Returns.csv\n",
      "Directory \"data\\player\\week1\" already exists.\n",
      "DataFrame for category \"Punting\" in unit \"player\" has been exported to data\\player\\week1\\Punting.csv\n",
      "Directory \"data\\player\\week1\" already exists.\n",
      "DataFrame for category \"Punt Returns\" in unit \"player\" has been exported to data\\player\\week1\\Punt Returns.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "level = \"player\"  # Replace with \"team\" or \"player\" as needed\n",
    "get_stats(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"data\\team\\week1\\offense\" has been created.\n",
      "Directory \"data\\team\\week1\\offense\" already exists.\n",
      "DataFrame for category \"passing\" in unit \"offense\" has been exported to data\\team\\week1\\offense\\passing.csv\n",
      "Directory \"data\\team\\week1\\offense\" already exists.\n",
      "Directory \"data\\team\\week1\\offense\" already exists.\n",
      "DataFrame for category \"rushing\" in unit \"offense\" has been exported to data\\team\\week1\\offense\\rushing.csv\n",
      "Directory \"data\\team\\week1\\offense\" already exists.\n",
      "Directory \"data\\team\\week1\\offense\" already exists.\n",
      "DataFrame for category \"receiving\" in unit \"offense\" has been exported to data\\team\\week1\\offense\\receiving.csv\n",
      "Directory \"data\\team\\week1\\offense\" already exists.\n",
      "Directory \"data\\team\\week1\\offense\" already exists.\n",
      "DataFrame for category \"scoring\" in unit \"offense\" has been exported to data\\team\\week1\\offense\\scoring.csv\n",
      "Directory \"data\\team\\week1\\offense\" already exists.\n",
      "Directory \"data\\team\\week1\\offense\" already exists.\n",
      "DataFrame for category \"downs\" in unit \"offense\" has been exported to data\\team\\week1\\offense\\downs.csv\n",
      "Directory \"data\\team\\week1\\defense\" has been created.\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "DataFrame for category \"passing\" in unit \"defense\" has been exported to data\\team\\week1\\defense\\passing.csv\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "DataFrame for category \"rushing\" in unit \"defense\" has been exported to data\\team\\week1\\defense\\rushing.csv\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "DataFrame for category \"receiving\" in unit \"defense\" has been exported to data\\team\\week1\\defense\\receiving.csv\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "DataFrame for category \"scoring\" in unit \"defense\" has been exported to data\\team\\week1\\defense\\scoring.csv\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "DataFrame for category \"tackles\" in unit \"defense\" has been exported to data\\team\\week1\\defense\\tackles.csv\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "DataFrame for category \"downs\" in unit \"defense\" has been exported to data\\team\\week1\\defense\\downs.csv\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "DataFrame for category \"fumbles\" in unit \"defense\" has been exported to data\\team\\week1\\defense\\fumbles.csv\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "Directory \"data\\team\\week1\\defense\" already exists.\n",
      "DataFrame for category \"interceptions\" in unit \"defense\" has been exported to data\\team\\week1\\defense\\interceptions.csv\n",
      "Directory \"data\\team\\week1\\special-teams\" has been created.\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "DataFrame for category \"field-goals\" in unit \"special-teams\" has been exported to data\\team\\week1\\special-teams\\field-goals.csv\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "DataFrame for category \"scoring\" in unit \"special-teams\" has been exported to data\\team\\week1\\special-teams\\scoring.csv\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "DataFrame for category \"kickoffs\" in unit \"special-teams\" has been exported to data\\team\\week1\\special-teams\\kickoffs.csv\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "DataFrame for category \"kickoff-returns\" in unit \"special-teams\" has been exported to data\\team\\week1\\special-teams\\kickoff-returns.csv\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "DataFrame for category \"punts\" in unit \"special-teams\" has been exported to data\\team\\week1\\special-teams\\punts.csv\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "Directory \"data\\team\\week1\\special-teams\" already exists.\n",
      "DataFrame for category \"punt-returns\" in unit \"special-teams\" has been exported to data\\team\\week1\\special-teams\\punt-returns.csv\n"
     ]
    }
   ],
   "source": [
    "level = \"team\"  # Replace with \"player\" or \"team\" as needed\n",
    "get_stats(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
