{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.nfl.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to get links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(level, season, base_url=\"https://www.nfl.com\"):\n",
    "    # Initialize a list to store the links\n",
    "    all_links = []\n",
    "\n",
    "    if level == \"player\":\n",
    "        # Request raw HTML\n",
    "        html = requests.get(\"https://www.nfl.com/stats/player-stats/\")\n",
    "        # Assuming your HTML is stored in a variable named html_content\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "        # Find the ul element with class 'd3-o-tabbed-controls-selector__list'\n",
    "        li_elements = soup.find_all('li', class_='d3-o-tabs__list-item')\n",
    "    elif level == \"team\":\n",
    "        # First get the base links for offense, defense, and special-teams tab\n",
    "        # Request raw HTML\n",
    "        html = requests.get(\"https://www.nfl.com/stats/team-stats/\")\n",
    "        # Assuming your HTML is stored in a variable named html_content\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "        # Find the ul element with class 'd3-o-tabbed-controls-selector__list'\n",
    "        ul_element = soup.find('ul', class_='d3-o-tabbed-controls-selector__list')\n",
    "        # Find all li elements within the ul element\n",
    "        li_elements = ul_element.find_all('li')\n",
    "\n",
    "    # Initialize a list to store the href values\n",
    "    href_values = []\n",
    "\n",
    "    # Iterate through the li elements and extract the href values from the a tags\n",
    "    for li in li_elements:\n",
    "        a_tag = li.find('a')\n",
    "        if a_tag:\n",
    "            href = a_tag['href']\n",
    "            href_values.append(href)\n",
    "\n",
    "    # Loop through href_values and fetch links for each URL\n",
    "    for href in href_values:\n",
    "        url = base_url + href\n",
    "        html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "        a_elements = soup.find_all('li', class_='d3-o-tabs__list-item')\n",
    "        links = [base_url + element.find('a')['href'] for element in a_elements]\n",
    "        all_links.extend(links)  # Append the links to the all_links list\n",
    "    \n",
    "    # Replace \"2023\" with the value of the season variable we want to scrape\n",
    "    all_links = [link.replace('2023', season) for link in all_links]\n",
    "    return all_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function to format links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated format_links function\n",
    "def format_links(level, season):\n",
    "    # Create a dictionary to store the links for each unit and its categories\n",
    "    unit_links = {}\n",
    "\n",
    "    if level == \"player\":\n",
    "        # Define the URL for the player level\n",
    "        all_links = get_links(level, season, base_url)  # Pass the URL as an argument\n",
    "\n",
    "        # Create a dictionary to store the links\n",
    "        team_stats_dict = {}\n",
    "\n",
    "        for link in all_links:\n",
    "            # Split the link by \"/\"\n",
    "            parts = link.split('/')\n",
    "            # Get the keys and values\n",
    "            unit = \"individual\" # e.g., individual, offense, defense, special-teams\n",
    "            category = parts[6]\n",
    "            url = link\n",
    "            # Add to the dictionary\n",
    "            if unit not in team_stats_dict:\n",
    "                team_stats_dict[unit] = {}\n",
    "            team_stats_dict[unit][category] = url\n",
    "\n",
    "    if level == \"team\":\n",
    "        all_links = get_links(level, season, base_url)\n",
    "\n",
    "        # Create a dictionary to store the links\n",
    "        team_stats_dict = {}\n",
    "\n",
    "        for link in all_links:\n",
    "            # Split the link by \"/\"\n",
    "            parts = link.split('/')\n",
    "            # Get the keys and values\n",
    "            unit = parts[5] # e.g., offense, defense, special-teams\n",
    "            category = parts[6] # e.g., passing, rushing etc.\n",
    "            url = link\n",
    "            # Add to the dictionary\n",
    "            if unit not in team_stats_dict:\n",
    "                team_stats_dict[unit] = {}\n",
    "            team_stats_dict[unit][category] = url\n",
    "\n",
    "    # Get stat category names and update unit_links\n",
    "    stat_cols = {}\n",
    "\n",
    "    for outer_key, inner_dict in team_stats_dict.items():\n",
    "        inner_keys = list(inner_dict.keys())\n",
    "        \n",
    "        if outer_key in stat_cols:\n",
    "            stat_cols[outer_key].extend(inner_keys)\n",
    "        else:\n",
    "            stat_cols[outer_key] = inner_keys\n",
    "\n",
    "    # Update unit_links with the fetched links\n",
    "    unit_links = team_stats_dict\n",
    "\n",
    "    return unit_links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function to Check/Create Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create directories if they don't exist\n",
    "def create_directory_if_not_exists(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        try:\n",
    "            os.makedirs(directory_path)\n",
    "            print(f'Directory \"{directory_path}\" has been created.')\n",
    "        except OSError as e:\n",
    "            print(f'Error: Failed to create directory \"{directory_path}\".')\n",
    "            print(e)\n",
    "    else:\n",
    "        print(f'Directory \"{directory_path}\" already exists.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function to Scrape and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape and process data\n",
    "def scrape_and_process_data(link, unit, category, level, unit_directory_path):\n",
    "    # Request raw HTML for the current page\n",
    "    response = requests.get(link)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Create a BeautifulSoup object to parse the HTML\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Find all elements with the class 'd3-o-player-stats--detailed'\n",
    "        stats = soup.find_all(attrs={\"class\": f'd3-o-{level}-stats--detailed'})\n",
    "\n",
    "        # Initialize lists to collect data\n",
    "        stat_val = []\n",
    "        stat_col = []\n",
    "\n",
    "        # Loop through each <tr> element to extract and collect the text from <td> elements\n",
    "        for row in stats:\n",
    "            # This gets the stat names\n",
    "            header_cells = row.find_all('th')\n",
    "\n",
    "            if len(header_cells) > 0:\n",
    "                for cell in header_cells:\n",
    "                    stat_col.append(cell.get_text(strip=True))\n",
    "\n",
    "            # This gets the stats\n",
    "            data_cells = row.find_all('td')\n",
    "\n",
    "            if len(data_cells) > 0:\n",
    "                for cell in data_cells:\n",
    "                    stat_val.append(cell.get_text(strip=True))\n",
    "\n",
    "        # Determine the number of columns in each row\n",
    "        num_columns = len(stat_col) if stat_col else 1  # Use 1 if stat_col is empty\n",
    "        \n",
    "        # Split the list into rows\n",
    "        rows = [stat_val[i:i + num_columns] for i in range(0, len(stat_val), num_columns)]\n",
    "\n",
    "        # Create a DataFrame for the current category\n",
    "        df = pd.DataFrame(rows, columns=stat_col)\n",
    "        \n",
    "        # Check if the DataFrame has a \"Team\" column before attempting to remove the duplicated part\n",
    "        if 'Team' in df.columns:\n",
    "            # Remove duplicated part from the \"Team\" column\n",
    "            df['Team'] = df['Team'].apply(lambda x: x[:len(x)//2])\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        create_directory_if_not_exists(unit_directory_path)\n",
    "    \n",
    "        # Specify the file path within the unit's directory\n",
    "        csv_file_path = os.path.join(unit_directory_path, category + '.csv')\n",
    "\n",
    "        # Export the DataFrame to a CSV file\n",
    "        df.to_csv(csv_file_path, index=False)  # Set index=False to exclude the index column\n",
    "\n",
    "        print(f'DataFrame for category \"{category}\" in unit \"{unit}\" has been exported to {csv_file_path}')\n",
    "    else:\n",
    "        print(f\"Error: Unable to fetch the page for category '{category}' in unit '{unit}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function to  Initiate Scraping Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(level, season):\n",
    "    lst = [\"offense\", \"defense\", \"special-teams\"]\n",
    "\n",
    "    # Combine the base directory path with the current week for current season, else store data in reg (regular season)\n",
    "    global current_season\n",
    "    if season == current_season:\n",
    "        directory_path = os.path.join('data', season, level, 'week' + str(current_week))\n",
    "    elif season != current_season:\n",
    "        directory_path = os.path.join('data', season, level, 'reg')\n",
    "    \n",
    "    unit_links = format_links(level, season)\n",
    "\n",
    "    if level == \"team\":\n",
    "        for unit, categories in unit_links.items(): ## change to be same with player\n",
    "            for category, link in categories.items():\n",
    "\n",
    "                # Create a subdirectory for the current unit\n",
    "                unit_directory_path = os.path.join(directory_path, unit)\n",
    "                #create_directory_if_not_exists(unit_directory_path)\n",
    "\n",
    "\n",
    "                # Call scrape_and_process_data with individual category URLs\n",
    "                scrape_and_process_data(link, unit, category, level, unit_directory_path)\n",
    "                \n",
    "    elif level == \"player\":\n",
    "        for unit, categories in unit_links.items(): ## change to be same with player\n",
    "            for category, link in categories.items():\n",
    "                # Directly use the week1 directory for player-level data\n",
    "                unit_directory_path = directory_path\n",
    "\n",
    "                scrape_and_process_data(link, unit, category, level, unit_directory_path)\n",
    "    else:\n",
    "        print(\"Invalid level specified.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
